# Quality Evaluation Questionnaire for Experimental Studies

## 1. Do the authors clearly state the aims of the research?

1.1) Do the authors state research questions, e.g., related to time-to-market, cost, product quality, process quality, developer productivity, and developer skills?  
[X] No  
[ ] Yes  
[ ] Not applicable  

1.2) Do the authors state hypotheses and their underlying theories?  
[X] No  
[ ] Yes  
[ ] Not applicable  

---

## 2. Is there an adequate description of the context in which the research was carried out?

2.1) The industry in which products are used (e.g., banking, telecommunications, consumer goods, travel, etc.)  
[ ] No  
[X] Yes  
[ ] Not applicable  

> "Deep learning algorithms, such as ResNet [1], VGGNet [2] and DenseNet [3] have shown great potential in bird call recognition which is essential to bird population monitoring." (Tao et al., 2022, p. 1)

2.2) If applicable, the nature of the software development organization (e.g., in-house department or independent software supplier)  
[ ] No  
[ ] Yes  
[X] Not applicable  

2.3) The skills and experience of the subjects (e.g., with a language, a method, a tool, an application domain)  
[ ] No  
[ ] Yes  
[X] Not applicable  

2.4) The type of software products used (e.g., a design tool, a compiler)  
[ ] No  
[X] Yes  
[ ] Not applicable  

> "This work used a ResNet-18 structure formed by five stages, each block with convolution and batch norm layers with ReLU activation. The architecture accepts an input data of size 64 x 64. The training was done for 100 epochs. Adam optimizer was used to train the model with a learning rate of 10-3. The CNN classification model was built using Python v3.9 and Keras v2.9 packages³ in Tensorflow v2.4.14." (Tao et al., 2022, p. 3)

2.5) If applicable, the software processes being used (e.g., a company standard process, the quality assurance procedures, the configuration management process)  
[ ] No  
[ ] Yes  
[X] Not applicable  

---

## 3. Do the authors explain how experimental units were defined and selected?

3.1) Do the authors explain how experimental units were defined and selected?  
[X] No  
[ ] Yes  
[ ] Not applicable  

3.2) Do the authors state to what degree the experimental units are representative?  
[X] No  
[ ] Yes  
[ ] Not applicable  

3.3) Do the authors explain why the experimental units they selected were the most appropriate for providing insight into the type of knowledge sought by the experiment?  
[X] No  
[ ] Yes  
[ ] Not applicable  

3.4) Do the authors report the sample size?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> "The response measured are averaged over five measurement samples for power consumption and inference time." (Tao et al., 2022, p. 4)

---

## 4. Do the authors describe the design of the experiment?

4.1) Do the authors clearly describe the chosen design (blocking, within or between subject design, do treatments have levels)?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> "Table I results for each model metric show the 36 settings of the three model compression factors: pruning sparsity, weight quantization and activation quantization."

4.2) Do the authors define/describe all treatments and all controls?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> “Quantization-aware training was implemented with QKeras for the quantization of the weights and activations of the model. The 8-bit, 16-bit, and 32-bit representation of weights and activations are investigated to evaluate the changes in the model metrics.” (Tao et al., 2022, p. 3)

---

## 5. Do the authors describe the data collection procedures and define the measures?

5.1) Are all measures clearly defined (e.g., scale, unit, counting rules)?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> “Power consumption, mW (lower is better). The voltage drop during inference was measured by an oscilloscope and current sense resistor to calculate the power usage” (Tao et al., 2022, p. 4)

5.2) Is the form of the data clear (e.g., tape recording, video material, notes, etc.)?  
[ ] No  
[X] Yes  
[ ] Not applicable  

5.3) Are quality control methods used to ensure consistency, completeness, and accuracy of collected data?  
[X] No  
[ ] Yes  
[ ] Not applicable  

5.4) Do the authors report drop-outs?  
[ ] No  
[ ] Yes  
[X] Not applicable  

---

## 6. Do the authors define the data analysis procedures?

6.1) Do authors justify their choice / describe the procedures / provide references to descriptions of the procedures?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> "The dominance analysis procedure was developed for use with multiple regression by comparing pairs of predictors across all subsets of the predictors in a model to determine the additional contribution that each predictor makes to the prediction model [31]." (Tao et al., 2022, p. 4)

6.2) Do the authors report significance levels and effect sizes?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> "We used R v4.2.16 to conduct dominance analysis with a statistical significance level of p<0.05." (Tao et al., 2022, p. 4)

6.3) If outliers are mentioned and excluded from the analysis, is this justified?  
[ ] No  
[ ] Yes  
[X] Not applicable  

6.4) Do the authors report or give references to raw data and/or descriptive statistics?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> "TABLE I: Model metrics of the STM32H7A3 Nucleo-144 board running the trained 36 different model compression configurations applied to the ResNet-18 network." (Tao et al., 2022, p. 5)

---

## 7. Do the authors discuss potential experimenter bias?

7.1) Were the authors the developers of some or all of the treatments? If yes, do the authors discuss the implications anywhere in the paper?  
[ ] No  
[ ] Yes  
[X] Not applicable  

7.2) Was training and conduct equivalent for all treatment groups?  
[ ] No  
[ ] Yes  
[X] Not applicable  

7.3) Was there allocation concealment, i.e., did the researchers know to what treatment each subject was assigned?  
[ ] No  
[ ] Yes  
[X] Not applicable  

---

## 8. Do the authors discuss the limitations of their study?

8.1) Do the authors discuss external validity with respect to subjects, materials, and tasks?  
[X] No  
[ ] Yes  
[ ] Not applicable  

8.2) If the study was a quasi-experiment, do the authors discuss the design components that were used to address any study weaknesses?  
[X] No  
[ ] Yes  
[ ] Not applicable  

8.3) If the study used novel measures, is the construct validity of the measures discussed?  
[ ] No  
[ ] Yes  
[X] Not applicable  

---

## 9. Do the authors state the findings clearly?

9.1) Do the authors present results clearly?  
[ ] No  
[X] Yes  
[ ] Not applicable  

9.2) Do the authors present conclusions clearly?  
[ ] No  
[X] Yes  
[ ] Not applicable  

9.3) Are the conclusions warranted by the results and are the connections between the results and conclusions presented clearly?  
[ ] No  
[X] Yes  
[ ] Not applicable  

9.4) Do the authors discuss their conclusions in relation to the original research questions?  
[ ] No  
[X] Yes  
[ ] Not applicable  

9.5) Are limitations of the study discussed explicitly?  
[X] No  
[ ] Yes  
[ ] Not applicable  

---

## 10. Is there evidence that the results can be used by other researchers/practitioners?

10.1) Do the authors discuss whether or how the findings can be transferred to other populations, or consider other ways in which the research can be used?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> “Though as highlighted by [23], there is no ”one-size-fitsall” universal compression setting, our systematic approach is transferable to other neural network models and microcontrollers in other application domains” (Tao et al., 2022, p. 2)

10.2) To what extent do authors interpret results in the context of other studies / the existing body of knowledge?  
[ ] No  
[X] Yes  
[ ] Not applicable  

> “Our work aligns with the findings from the work conducted by Qin et al. [20].” (Tao et al., 2022, p. 7)
